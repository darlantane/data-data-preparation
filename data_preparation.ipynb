{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"magic commands\" to enable autoreload of your imported packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to load all 9 `.csv` files into 9 `pandas.DataFrame`s in a single dict named `data` where:\n",
    "- each **key** is the **cleaned name** of the csv file\n",
    "- each **value** is the **DataFrame** created from the csv\n",
    "\n",
    "```python\n",
    "data = { \n",
    "    'sellers': DataFrame1,\n",
    "    'orders': DataFrame2,\n",
    "    ...\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the variable `csv_path`, which stores the path to your `\"csv\" folder` as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Python's `pathlib` to handle our paths easily. Pathlib defines a very handy `Path` class.\n",
    "\n",
    "We can instantiate a `Path` by giving it a string defining our path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "csv_path = Path(\"~/.lewagon/olist/data/csv\").expanduser()\n",
    "csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_`PosixPath`_? That means it's a path in Posix format. POSIX (Portable Operating System Interface) is a standardized set of APIs and conventions for Unix-like operating systems to ensure compatibility and interoperability. Both Linux (e.g. Ubuntu on WSL) and macOS are POSIX-compliant.\n",
    "\n",
    "We use the `expanduser()` to expand the `~` into the actual absolute path of our home folder.\n",
    "\n",
    "We can now use the `iterdir()` method to list the files in our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = list(csv_path.iterdir())\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your code below. We try to load the first csv in the directory\n",
    "import pandas as pd\n",
    "pd.read_csv(file_paths[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the list `file_names` containing all csv file names in the csv directory\n",
    "\n",
    "- It should look like this `file_names = ['olist_sellers_dataset.csv', ....]`\n",
    "- You can start from `file_paths`\n",
    "- A `Path` has a `name`  property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Create the list of dict key `key_names` \n",
    "Starting from file_names and:\n",
    "- Removing its suffix \".csv\" when it exists\n",
    "- Removing its suffix \"_dataset.csv\" when it exists\n",
    "- Removing its prefix \"olist_\" when it exists\n",
    "\n",
    "<details>\n",
    "    <summary>- Hint - </summary>\n",
    "\n",
    "- `.replace()`\n",
    "    \n",
    "- `str` ings are iterables you can slice with [ ]\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Construct the dictionary `data`\n",
    "\n",
    "```python\n",
    "data = { \n",
    "    'sellers': DataFrame1,\n",
    "    'orders': DataFrame2,\n",
    "    'order_items': DataFrame3,\n",
    "    ...\n",
    "    }\n",
    "```\n",
    "Where `DataFrame1`, `DataFrame2`, ... should be actual `pandas.DataFrame`s.\n",
    "\n",
    "<details>\n",
    "    <summary>‚ñ∏ Hint</summary>\n",
    "\n",
    "The `zip()` method is very useful to iterate over two lists\n",
    "```python\n",
    "for (x, y) in zip(['a','b','c'], [1,2,3]):\n",
    "    print(x,y)\n",
    "\n",
    "# returns ('a', 1), ('b', 2), ('c', 3)\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implement the method `get_data()` in `olist/data.py`\n",
    "\n",
    "Time to move our logic from the notebook into our `.py` files. This will allow us to easily load the data in the new notebooks we'll create througout this module. \n",
    "\n",
    "Go and open the `olist/data.py` file in this module's folder (it's two levels up from this notebook), and start moving the code you have written in this notebook to the `get_data()` method. Skip the lines we wrote to test our code (no need to display lists and DataFrames in the `.py` file).\n",
    "\n",
    "The function should return the dictionary with DataFrames when calling it. Try it out with one of the csvs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from olist.data import Olist\n",
    "Olist().get_data()['sellers'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "from olist.data import Olist\n",
    "data = Olist().get_data()\n",
    "result = ChallengeResult('get_data',\n",
    "    keys_len=len(data),\n",
    "    keys=sorted(list(data.keys())),\n",
    "    columns=sorted(list(data['sellers'].columns)),\n",
    "    vars_used=Olist.get_data.__code__.co_names\n",
    "    )\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìThis piece of code needs to work from anywhere on your machine, not only in this notebook.\n",
    "- Open a new terminal\n",
    "- Go to your home folder `cd`\n",
    "- Launch an `ipython` session\n",
    "- Test the two lines of code above üëÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations !\n",
    "\n",
    "üíæ Don't forget to commit & push: \n",
    "* this `data_preparation.ipynb` notebook and the `tests/get_data.pickle` test results in the challenge folder\n",
    "* as well as `data.py` in the `03-Decision-Science/olist` folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
